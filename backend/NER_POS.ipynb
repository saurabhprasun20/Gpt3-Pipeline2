{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nerList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                               selftext\n0     So I finally got my pulmonolgist appt after ye...\n1     A decade ago an allergist told me I dont have ...\n2     Howdy there is there a way to improve my asthm...\n3     So I‚Äôm just enjoying the evening and I start...\n4     Does anyone else get a heavy feeling or feel l...\n...                                                 ...\n3474  Anyone else have an advair or wixela inhub inh...\n3475  I‚Äôm new to this inhaler thing. I‚Äôm guessin...\n3476  I used a DPI with a 200mg capsule of my preven...\n3477  I am planning to get vaccinated soon (just wai...\n3478  That was what a pulmonologist told me yesterda...\n\n[3479 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>selftext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>So I finally got my pulmonolgist appt after ye...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A decade ago an allergist told me I dont have ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Howdy there is there a way to improve my asthm...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>So I‚Äôm just enjoying the evening and I start...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Does anyone else get a heavy feeling or feel l...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3474</th>\n      <td>Anyone else have an advair or wixela inhub inh...</td>\n    </tr>\n    <tr>\n      <th>3475</th>\n      <td>I‚Äôm new to this inhaler thing. I‚Äôm guessin...</td>\n    </tr>\n    <tr>\n      <th>3476</th>\n      <td>I used a DPI with a 200mg capsule of my preven...</td>\n    </tr>\n    <tr>\n      <th>3477</th>\n      <td>I am planning to get vaccinated soon (just wai...</td>\n    </tr>\n    <tr>\n      <th>3478</th>\n      <td>That was what a pulmonologist told me yesterda...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3479 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1 =pd.read_csv(\"Asthma-QA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(513, 1)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pos_dict = {}\n",
    "verb_noun_rel_dict = {}\n",
    "verb_token_list = [\"VB\", \"VBG\", \"VBD\", \"VBN\", \"VBP\", \"VBZ\"]\n",
    "noun_token_list = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
    "\n",
    "def pos_tagging(tokens_tag, pos_dict):\n",
    "    for item in tokens_tag:\n",
    "        if item[1] in pos_dict.keys():\n",
    "            val_list = pos_dict.get(item[1])\n",
    "            val_list.append(item[0])\n",
    "        else:\n",
    "            temp_list = []\n",
    "            temp_list.append(item[0])\n",
    "            pos_dict[item[1]] = temp_list\n",
    "\n",
    "def find_vn_relation(tokens_tag):\n",
    "    temp_verb = ''\n",
    "    temp_noun = ''\n",
    "    for item in tokens_tag:\n",
    "        if item[1] in verb_token_list:\n",
    "            temp_verb = wordnet_lemmatizer.lemmatize(item[0].lower())\n",
    "        if item[1] in noun_token_list:\n",
    "            temp_noun = wordnet_lemmatizer.lemmatize(item[0].lower())\n",
    "            # print(temp_verb,'->', temp_noun)\n",
    "            if temp_verb != '' and temp_verb != None:\n",
    "                # print(temp_verb)\n",
    "                if temp_noun!='' and temp_noun!=None:\n",
    "                    # print(temp_noun)\n",
    "                    if temp_verb in verb_noun_rel_dict.keys():\n",
    "                        val_list = verb_noun_rel_dict.get(temp_verb)\n",
    "                        # print(val_list)\n",
    "                        # print(temp_verb,'->', temp_noun)\n",
    "                        if temp_noun not in val_list:\n",
    "                            val_list.append(temp_noun)\n",
    "                    else:\n",
    "                        temp_list = []\n",
    "                        temp_list.append(temp_noun)\n",
    "                        verb_noun_rel_dict[temp_verb] = temp_list\n",
    "                        # if temp_verb == 'severe':\n",
    "                        #     print(\"its here\")\n",
    "                        #     print(temp_noun)\n",
    "                        #     print(\"aaa\")\n",
    "                        #     print(verb_noun_rel_dict['severe'])\n",
    "                        #     break\n",
    "#\n",
    "for index, row in df.iterrows():\n",
    "    row['selftext'] = row['selftext'].translate(str.maketrans('', '', string.punctuation))\n",
    "    text = row['selftext'].split()\n",
    "    tokens_tag = pos_tag(text)\n",
    "    find_vn_relation(tokens_tag)\n",
    "    pos_tagging(tokens_tag, pos_dict)\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    row['Question'] = row['Question'].translate(str.maketrans('', '', string.punctuation))\n",
    "    text = row['Question'].split()\n",
    "    tokens_tag = pos_tag(text)\n",
    "    find_vn_relation(tokens_tag)\n",
    "    pos_tagging(tokens_tag, pos_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp_list = verb_noun_rel_dict[\"play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['tylenol',\n 'without',\n 'everyday',\n 'daycare',\n 'symptom',\n 'fine',\n 'sport',\n 'side',\n 'effect',\n 'intensity',\n 'cold',\n 'bit',\n 'role',\n 'roll',\n 'condition',\n 'anyone',\n 'guitar',\n 'hockey',\n 'soccer',\n 'college',\n 'any',\n 'help',\n 'ive',\n 'asthma',\n 'part',\n 'pain',\n 'susceptibility',\n 'incidence',\n 'inflammation',\n 'asthma142204',\n 'anticholinergic',\n 'medication',\n 'ipratropium',\n 'bromide',\n 'exacerbation',\n 'use',\n 'testing',\n 'factor']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"football\" in temp_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pos_dict = {}\n",
    "# for item in tokens_tag:\n",
    "#     if item[1] in pos_dict.keys():\n",
    "#         val_list = pos_dict.get(item[1])\n",
    "#         val_list.append(item[0])\n",
    "#     else:\n",
    "#         temp_list = []\n",
    "#         temp_list.append(item[0])\n",
    "#         pos_dict[item[1]] = temp_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "should include - NN, NNS, NNP, NNPS, VB, VBG, VBD, VBN, VBP, VBZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noun_list = []\n",
    "verb_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noun_list = pos_dict.get('NN')+pos_dict.get('NNS')+pos_dict.get('NNP')+pos_dict.get('NNPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "verb_list = pos_dict.get('VB') + pos_dict.get('VBG') + pos_dict.get('VBD') + pos_dict.get('VBN') + pos_dict.get('VBP') + pos_dict.get('VBZ')\n",
    "# verb_list = pos_dict.get('VBG'))\n",
    "# verb_list.append(pos_dict.get('VBD'))\n",
    "# verb_list.append(pos_dict.get('VBN'))\n",
    "# verb_list.append(pos_dict.get('VBP'))\n",
    "# verb_list.append(pos_dict.get('VBZ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "verb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(noun_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(noun_list)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compare Noun and verb separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "txt = \"Sukanya, Rajib and Naba are my good friends. \" \\\n",
    "\t\"Sukanya is getting married next year. \" \\\n",
    "\t\"Marriage is a big step in one’s life.\" \\\n",
    "\t\"It is both exciting and frightening. \" \\\n",
    "\t\"But friendship is a sacred bond between people.\" \\\n",
    "\t\"It is a special kind of love between us. \" \\\n",
    "\t\"Many of you must have tried searching for a friend \"\\\n",
    "\t\"but never found the right one.\"\n",
    "\n",
    "# sent_tokenize is one of instances of\n",
    "# PunktSentenceTokenizer from the nltk.tokenize.punkt module\n",
    "\n",
    "tokenized = sent_tokenize(txt)\n",
    "for i in tokenized:\n",
    "\t\n",
    "\t# Word tokenizers is used to find the words\n",
    "\t# and punctuation in a string\n",
    "\twordsList = nltk.word_tokenize(i)\n",
    "\n",
    "\t# removing stop words from wordList\n",
    "\twordsList = [w for w in wordsList if not w in stop_words]\n",
    "\n",
    "\t# Using a Tagger. Which is part-of-speech\n",
    "\t# tagger or POS-tagger.\n",
    "\ttagged = nltk.pos_tag(wordsList)\n",
    "\n",
    "\tprint(tagged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from flair.data import Sentence\n",
    "# from flair.models import SequenceTagger\n",
    "\n",
    "# # load tagger\n",
    "# tagger = SequenceTagger.load(\"flair/pos-english\")\n",
    "\n",
    "# # make example sentence\n",
    "# sentence = Sentence(\"I love Berlin.\")\n",
    "\n",
    "# # predict NER tags\n",
    "# tagger.predict(sentence)\n",
    "\n",
    "# # print sentence\n",
    "# print(sentence)\n",
    "\n",
    "# # print predicted NER spans\n",
    "# print('The following NER tags are found:')\n",
    "# # iterate over entities and print\n",
    "# for entity in sentence.get_spans('pos'):\n",
    "#     print(entity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca41db331e23b6fc476d9fbae5f7668697635e2a6681d42cf98d469131148d99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}